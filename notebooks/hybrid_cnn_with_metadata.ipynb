{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hybrid_cnn_with_metadata.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOSjfr8/JFbuxlinfZBP34F"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c839070a300c4b8ea86064eae2d245d9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_591398a64e584d2f8acb600fb79c8c4b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4dc1761b7a244fe686c8935ae863c40c","IPY_MODEL_05213d8e181e42299e48212b8edb7ccd","IPY_MODEL_c17453b1c7c24933b2c17b241fad1ac2"]}},"591398a64e584d2f8acb600fb79c8c4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4dc1761b7a244fe686c8935ae863c40c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_44c225f4f8f448959eeacf83e15ee994","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: ","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_81c72423fb924c78ae79fd7259d62f6b"}},"05213d8e181e42299e48212b8edb7ccd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_091b871b92634362b8545cf15f7c9bb8","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":2326,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2326,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bcded8c3a741415eae6e1ab6bf992eef"}},"c17453b1c7c24933b2c17b241fad1ac2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ab0f1a69fd084dd78e5c016a393a25ed","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 6.41k/? [00:00&lt;00:00, 135kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_400ff1791cdc41409746270bb72cd7ee"}},"44c225f4f8f448959eeacf83e15ee994":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"81c72423fb924c78ae79fd7259d62f6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"091b871b92634362b8545cf15f7c9bb8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bcded8c3a741415eae6e1ab6bf992eef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ab0f1a69fd084dd78e5c016a393a25ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"400ff1791cdc41409746270bb72cd7ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5e63bc9abad74a9ebe35f11ce8feaf70":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e598a1677a5c48e1a9cfcb1b07d73be0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9d47b03fcf0d4244bcef76a001fed6ca","IPY_MODEL_ad04995517e8424a96de93efcd4177df","IPY_MODEL_ff7fbc2b4ee24a949e547d648cf70c8b"]}},"e598a1677a5c48e1a9cfcb1b07d73be0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9d47b03fcf0d4244bcef76a001fed6ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fa158472eb43450f97c244b5504b38b8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: ","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_550fc333aaaf4918a7997d740386e640"}},"ad04995517e8424a96de93efcd4177df":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ba31e197633b48d681b1e25148ea578f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1680,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1680,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ee27a618d57944d7970b21f8c066f9b2"}},"ff7fbc2b4ee24a949e547d648cf70c8b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8d0ddafeb9904a14b28877794f6d73f5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4.03k/? [00:00&lt;00:00, 86.4kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5c61dfa7bd1b455d969424ded1f02a0a"}},"fa158472eb43450f97c244b5504b38b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"550fc333aaaf4918a7997d740386e640":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ba31e197633b48d681b1e25148ea578f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ee27a618d57944d7970b21f8c066f9b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8d0ddafeb9904a14b28877794f6d73f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5c61dfa7bd1b455d969424ded1f02a0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b196a7188c9b4da9819bb3dbaec5917b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a15e20a6890c479b9ff2c030d7fcc584","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d2f2db27d87f4a47b87dd6cd9fab9f29","IPY_MODEL_2ad16230ef834c0b8fd88728dbf79ea2","IPY_MODEL_6746d66c3c1849df9d6153d9fc487bc5"]}},"a15e20a6890c479b9ff2c030d7fcc584":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d2f2db27d87f4a47b87dd6cd9fab9f29":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_309f8146423c490a8c9468f7f6885f40","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_587d147891bd4c2eb1cb555dd13fac27"}},"2ad16230ef834c0b8fd88728dbf79ea2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_abee1b2148564a73850eaa268ffd6428","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1013571,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1013571,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1c2fffee520846288ad76d1a1fd954c3"}},"6746d66c3c1849df9d6153d9fc487bc5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_29d08dc5124f4e5b89d7abbb352af77d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.01M/1.01M [00:00&lt;00:00, 3.81MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_14f89f6c5613411793fc7d64d20cb5ab"}},"309f8146423c490a8c9468f7f6885f40":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"587d147891bd4c2eb1cb555dd13fac27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"abee1b2148564a73850eaa268ffd6428":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1c2fffee520846288ad76d1a1fd954c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"29d08dc5124f4e5b89d7abbb352af77d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"14f89f6c5613411793fc7d64d20cb5ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d7e114e1da1e40119ad1469672268934":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_edc9446cc3a441abb4e1490e033955eb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_49453c16062c4e7fb37a4ee219c40e21","IPY_MODEL_233af613935741fda29eb6961ef374e0","IPY_MODEL_c6867f6825d848ee998beaba3dcb1a63"]}},"edc9446cc3a441abb4e1490e033955eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"49453c16062c4e7fb37a4ee219c40e21":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_db94bbe8b63f400e9b5e6f3ef4fff2fe","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f35c7513d7864f6aa186b97fa3b6f84e"}},"233af613935741fda29eb6961ef374e0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_92e3faa6b3e94d0faffdc233436c1611","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bcd36ca90192400dbc4b2ebada0291f7"}},"c6867f6825d848ee998beaba3dcb1a63":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ba7a89576667424abbf121059f594886","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9644/0 [00:01&lt;00:00, 8068.39 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bcb142075fc84ab2813792dbcf69613f"}},"db94bbe8b63f400e9b5e6f3ef4fff2fe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f35c7513d7864f6aa186b97fa3b6f84e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"92e3faa6b3e94d0faffdc233436c1611":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bcd36ca90192400dbc4b2ebada0291f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":"20px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ba7a89576667424abbf121059f594886":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bcb142075fc84ab2813792dbcf69613f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f777855fa940472fabf67ae24b654ca2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b60b5d3047064e4899ae2e5a628f2a78","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ab4c6691fbbf45459b77202aadd68a7f","IPY_MODEL_829ce236358c4b828876065fd0580fd2","IPY_MODEL_877a17d569d943b1a533c65ccba7436f"]}},"b60b5d3047064e4899ae2e5a628f2a78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ab4c6691fbbf45459b77202aadd68a7f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cce8258d802f43ddb8735ef0770fecc2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_345f5a1e6f0d4742913a8fa0b92df44b"}},"829ce236358c4b828876065fd0580fd2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_96cf45ce7d634135ab01761fcc3f749c","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_98c63caca89244159e7d1a26b4245afe"}},"877a17d569d943b1a533c65ccba7436f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f26445929ccb47a3a8199e78f47dd9ad","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 880/0 [00:00&lt;00:00, 4852.59 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_38905bbc8ca442c2ac4d59c54645917f"}},"cce8258d802f43ddb8735ef0770fecc2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"345f5a1e6f0d4742913a8fa0b92df44b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"96cf45ce7d634135ab01761fcc3f749c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"98c63caca89244159e7d1a26b4245afe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":"20px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f26445929ccb47a3a8199e78f47dd9ad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"38905bbc8ca442c2ac4d59c54645917f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"38591424262d46dbbca18a125e7ea19e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_188599f4d870448f9984501589c7fb96","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5afcb671eeb64a7eaa42774b90d089ad","IPY_MODEL_0d3b61fa44564bddaa3eca2b7d79f48d","IPY_MODEL_b6ea2e6a56d64c299f49791d2285841f"]}},"188599f4d870448f9984501589c7fb96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5afcb671eeb64a7eaa42774b90d089ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6d343a4714674e16835d5da0a44de71f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f295d4f8e39b4bc082418674a2bc0cd3"}},"0d3b61fa44564bddaa3eca2b7d79f48d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_34a87cddedf0427e8e95e428fe24a515","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4fdcc23e54fa43489f04a78b2d8636e4"}},"b6ea2e6a56d64c299f49791d2285841f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8caf008f68e74cb7a8d4e500a75df026","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 859/0 [00:00&lt;00:00, 4754.29 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3290aa60489946438ab89b2115c3a2ce"}},"6d343a4714674e16835d5da0a44de71f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f295d4f8e39b4bc082418674a2bc0cd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"34a87cddedf0427e8e95e428fe24a515":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4fdcc23e54fa43489f04a78b2d8636e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":"20px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8caf008f68e74cb7a8d4e500a75df026":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3290aa60489946438ab89b2115c3a2ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"BH5ouZT_tMnu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638748717057,"user_tz":300,"elapsed":14270,"user":{"displayName":"Yixuan Meng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00008408025985696509"}},"outputId":"0e81f40f-d0cb-458d-c849-b46babd70735"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RYLPtuoogjKe","executionInfo":{"status":"ok","timestamp":1638748734030,"user_tz":300,"elapsed":16977,"user":{"displayName":"Yixuan Meng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00008408025985696509"}},"outputId":"59a0944e-f8a8-438e-f66f-f61a2e3c1fbf"},"source":["!pip install datasets\n","import gensim\n","import pandas as pd\n","import argparse\n","import numpy as np\n","from collections import Counter\n","from datasets import load_dataset\n","import os\n","import torch\n","import pickle\n","import re\n","import time\n","import copy\n","import math\n","from torch.utils.data import DataLoader, Dataset\n","import torch.optim as optimizer \n","import torch.nn.functional as F\n","from torch import nn\n","from sklearn.metrics import accuracy_score\n","\n","import seaborn as sns\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","plt.rcParams['font.family'] = \"sans-serif\"\n","plt.rcParams['font.sans-serif'] = ['Times New Roman']\n","sns.set_style(\"whitegrid\")\n","sns.set_style({'font.family':'serif', 'font.serif':'Times New Roman'})\n","sns.set(font_scale=1.2)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-1.16.1-py3-none-any.whl (298 kB)\n","\u001b[K     |████████████████████████████████| 298 kB 5.2 MB/s \n","\u001b[?25hCollecting xxhash\n","  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n","\u001b[K     |████████████████████████████████| 243 kB 42.1 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.8.2)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 38.6 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.1.0\n","  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 432 kB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Collecting fsspec[http]>=2021.05.0\n","  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 46.6 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.8)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.2.0)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 51.8 MB/s \n","\u001b[?25hCollecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n","\u001b[K     |████████████████████████████████| 160 kB 47.4 MB/s \n","\u001b[?25hCollecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n","\u001b[K     |████████████████████████████████| 192 kB 47.9 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.6.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, huggingface-hub, datasets\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.1 asynctest-0.13.0 datasets-1.16.1 frozenlist-1.2.0 fsspec-2021.11.1 huggingface-hub-0.2.1 multidict-5.2.0 xxhash-2.0.2 yarl-1.7.2\n"]}]},{"cell_type":"code","metadata":{"id":"4F2KWFb0gvx4"},"source":["data_dir = '/content/gdrive/MyDrive/530proj_me'\n","def clean_text(w):\n","    return re.sub(\n","            r\"([.,'!?\\\"()*#:;])\",\n","            '',\n","            w.lower()\n","            ).replace('-', ' ').replace('/', ' ')\n","def preprocessing(train=False, eval=False, test=False):\n","  # label col:  \"pants-fire\" : 0, \"false\" : 1, \"barely-true\" : 2, \"half-true\" : 3, \"mostly-true\" : 4, \"true\" : 5\n","  if train:\n","    current_dataset = load_dataset(\"liar\", split=\"train\")\n","  if eval:\n","    current_dataset = load_dataset('liar', split='validation')\n","  if test:\n","    current_dataset = load_dataset('liar', split='test')\n","  return current_dataset\n","\n","def get_word2vec_embedding(statements, data_dir):\n","  token_file = os.path.join(data_dir,'token_to_ix.pkl')\n","  w2v_file = os.path.join(data_dir,'train_w2v.npy')\n","\n","  if os.path.exists(w2v_file) and os.path.exists(token_file):\n","        print(\"Loading train language files\")\n","        return pickle.load(open(token_file, \"rb\")), np.load(w2v_file)\n","\n","  token2ix = {'PAD': 0, 'UNK': 1}\n","  for s in statements:\n","    s = clean_text(s).split()\n","    for word in s:\n","      if word not in token2ix:\n","        token2ix[word] = len(token2ix)\n","  ix2token = {token2ix[k]: k for k in token2ix.keys()}\n","  w2v_path = '/content/gdrive/MyDrive/530project/GoogleNews-vectors-negative300.bin.gz'\n","  w2vmodel = gensim.models.KeyedVectors.load_word2vec_format(w2v_path, binary=True)\n","  pretrained_emb = torch.randn([len(token2ix),300])\n","  for i in range(len(token2ix)):\n","    word = ix2token[i]\n","    if word in w2vmodel:\n","      vec = w2vmodel[word]\n","      pretrained_emb[i, :] = torch.from_numpy(vec)\n","  np.save(w2v_file, pretrained_emb)\n","  pickle.dump(token2ix, open(token_file, \"wb\"))\n","  return token2ix, pretrained_emb\n","\n","def embed_text(x, max_len, token2ix):\n","  ques_ix = np.zeros(max_len, np.int64)\n","  x = clean_text(x).split()\n","  for ix, word in enumerate(x):\n","    if word in token2ix:\n","      ques_ix[ix] = token2ix[word]\n","    else:\n","      ques_ix[ix] = 1\n","    if ix + 1 == max_len:\n","      break\n","  return ques_ix\n","def category_from_output(output):\n","  res = []\n","  for i in output:\n","    top_n, top_i = i.topk(1)\n","    category_i = top_i[0].item()\n","    res.append(category_i)\n","  return res"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":289,"referenced_widgets":["c839070a300c4b8ea86064eae2d245d9","591398a64e584d2f8acb600fb79c8c4b","4dc1761b7a244fe686c8935ae863c40c","05213d8e181e42299e48212b8edb7ccd","c17453b1c7c24933b2c17b241fad1ac2","44c225f4f8f448959eeacf83e15ee994","81c72423fb924c78ae79fd7259d62f6b","091b871b92634362b8545cf15f7c9bb8","bcded8c3a741415eae6e1ab6bf992eef","ab0f1a69fd084dd78e5c016a393a25ed","400ff1791cdc41409746270bb72cd7ee","5e63bc9abad74a9ebe35f11ce8feaf70","e598a1677a5c48e1a9cfcb1b07d73be0","9d47b03fcf0d4244bcef76a001fed6ca","ad04995517e8424a96de93efcd4177df","ff7fbc2b4ee24a949e547d648cf70c8b","fa158472eb43450f97c244b5504b38b8","550fc333aaaf4918a7997d740386e640","ba31e197633b48d681b1e25148ea578f","ee27a618d57944d7970b21f8c066f9b2","8d0ddafeb9904a14b28877794f6d73f5","5c61dfa7bd1b455d969424ded1f02a0a","b196a7188c9b4da9819bb3dbaec5917b","a15e20a6890c479b9ff2c030d7fcc584","d2f2db27d87f4a47b87dd6cd9fab9f29","2ad16230ef834c0b8fd88728dbf79ea2","6746d66c3c1849df9d6153d9fc487bc5","309f8146423c490a8c9468f7f6885f40","587d147891bd4c2eb1cb555dd13fac27","abee1b2148564a73850eaa268ffd6428","1c2fffee520846288ad76d1a1fd954c3","29d08dc5124f4e5b89d7abbb352af77d","14f89f6c5613411793fc7d64d20cb5ab","d7e114e1da1e40119ad1469672268934","edc9446cc3a441abb4e1490e033955eb","49453c16062c4e7fb37a4ee219c40e21","233af613935741fda29eb6961ef374e0","c6867f6825d848ee998beaba3dcb1a63","db94bbe8b63f400e9b5e6f3ef4fff2fe","f35c7513d7864f6aa186b97fa3b6f84e","92e3faa6b3e94d0faffdc233436c1611","bcd36ca90192400dbc4b2ebada0291f7","ba7a89576667424abbf121059f594886","bcb142075fc84ab2813792dbcf69613f","f777855fa940472fabf67ae24b654ca2","b60b5d3047064e4899ae2e5a628f2a78","ab4c6691fbbf45459b77202aadd68a7f","829ce236358c4b828876065fd0580fd2","877a17d569d943b1a533c65ccba7436f","cce8258d802f43ddb8735ef0770fecc2","345f5a1e6f0d4742913a8fa0b92df44b","96cf45ce7d634135ab01761fcc3f749c","98c63caca89244159e7d1a26b4245afe","f26445929ccb47a3a8199e78f47dd9ad","38905bbc8ca442c2ac4d59c54645917f","38591424262d46dbbca18a125e7ea19e","188599f4d870448f9984501589c7fb96","5afcb671eeb64a7eaa42774b90d089ad","0d3b61fa44564bddaa3eca2b7d79f48d","b6ea2e6a56d64c299f49791d2285841f","6d343a4714674e16835d5da0a44de71f","f295d4f8e39b4bc082418674a2bc0cd3","34a87cddedf0427e8e95e428fe24a515","4fdcc23e54fa43489f04a78b2d8636e4","8caf008f68e74cb7a8d4e500a75df026","3290aa60489946438ab89b2115c3a2ce"]},"id":"V-PrsnO3g6Xw","executionInfo":{"status":"ok","timestamp":1638748742185,"user_tz":300,"elapsed":8017,"user":{"displayName":"Yixuan Meng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00008408025985696509"}},"outputId":"c56ac92f-0855-4aa3-ab8a-6a551d3752c1"},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","EMBEDDING_DIM = 300\n","BATCH_SIZE = 64\n","LEARNING_RATE = 0.005\n","EPOCH = 11\n","\n","train_dataset = pd.DataFrame(preprocessing(train=True))\n","statements = train_dataset['statement']\n","token2ix, pretrained_emb = get_word2vec_embedding(statements, data_dir)\n","print(pretrained_emb.shape) # (len(vocab), embedding_dim)\n","lengths = [len(x.split()) for x in statements]\n","max_len = int(np.percentile(lengths,90))\n","\n","train_dataset['embedded'] = train_dataset['statement'].apply(lambda x: embed_text(x, max_len, token2ix))\n","dev_dataset = pd.DataFrame(preprocessing(eval=True))\n","dev_dataset['embedded'] = dev_dataset['statement'].apply(lambda x: embed_text(x, max_len, token2ix))\n","test_dataset = pd.DataFrame(preprocessing(test=True))\n","test_dataset['embedded'] = test_dataset['statement'].apply(lambda x: embed_text(x, max_len, token2ix))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c839070a300c4b8ea86064eae2d245d9","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/2.33k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5e63bc9abad74a9ebe35f11ce8feaf70","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.68k [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Using custom data configuration default\n"]},{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset liar/default (download: 989.82 KiB, generated: 3.26 MiB, post-processed: Unknown size, total: 4.22 MiB) to /root/.cache/huggingface/datasets/liar/default/1.0.0/479463e757b7991eed50ffa7504d7788d6218631a484442e2098dabbf3b44514...\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b196a7188c9b4da9819bb3dbaec5917b","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.01M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d7e114e1da1e40119ad1469672268934","version_minor":0,"version_major":2},"text/plain":["0 examples [00:00, ? examples/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f777855fa940472fabf67ae24b654ca2","version_minor":0,"version_major":2},"text/plain":["0 examples [00:00, ? examples/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"38591424262d46dbbca18a125e7ea19e","version_minor":0,"version_major":2},"text/plain":["0 examples [00:00, ? examples/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset liar downloaded and prepared to /root/.cache/huggingface/datasets/liar/default/1.0.0/479463e757b7991eed50ffa7504d7788d6218631a484442e2098dabbf3b44514. Subsequent calls will reuse this data.\n","Loading train language files\n","(12969, 300)\n"]},{"output_type":"stream","name":"stderr","text":["Using custom data configuration default\n","Reusing dataset liar (/root/.cache/huggingface/datasets/liar/default/1.0.0/479463e757b7991eed50ffa7504d7788d6218631a484442e2098dabbf3b44514)\n","Using custom data configuration default\n","Reusing dataset liar (/root/.cache/huggingface/datasets/liar/default/1.0.0/479463e757b7991eed50ffa7504d7788d6218631a484442e2098dabbf3b44514)\n"]}]},{"cell_type":"code","metadata":{"id":"c6yxG9tYiJqS"},"source":["def process_col(current_dataset, train = False, col_cnts = None, col = 'speaker'):\n","  if train:\n","    col_cnt = Counter(current_dataset[col])\n","    col_cnt = sorted(col_cnt.items(), key = lambda kv: kv[1], reverse=True)\n","    # elif col == 'speaker':\n","    col_cnt = {j[0]:idx for idx, j in enumerate([i for i in col_cnt if i[1]>60])}\n","  else:\n","    col_cnt = col_cnts[col]\n","  \n","  def col2ix(x):\n","    if x in col_cnt:\n","      return col_cnt[x]\n","    return len(col_cnt.keys())\n","  current_dataset[col + '_'] = current_dataset[col].apply(lambda x: col2ix(x))\n","  dummies = pd.get_dummies(current_dataset[col+'_'], prefix=col)\n","  names = list(dummies.columns)\n","  current_dataset = pd.concat((current_dataset,dummies),axis = 1)\n","  return current_dataset, names, col_cnt\n","\n","def process_metadata(current_dataset, meta_cols, train = False, col_cnts = None):\n","  dummy_name = []\n","  if train: col_cnts = {}\n","  for col in meta_cols:\n","    current_dataset, names, col_cnt = process_col(current_dataset, train = train, col_cnts = col_cnts, col = col)\n","    dummy_name += names\n","    if train: col_cnts[col] = col_cnt\n","  return current_dataset, dummy_name, col_cnts\n","  \n","meta_cols = ['subject','speaker','job_title','state_info','party_affiliation','context']\n","train_dataset_meta, dummy_name, col_cnts = process_metadata(train_dataset, meta_cols, train = True, col_cnts = None)\n","dev_dataset_meta, _, _ = process_metadata(dev_dataset,meta_cols, train = False, col_cnts = col_cnts)\n","test_dataset_meta, _, _ = process_metadata(test_dataset,meta_cols, train = False, col_cnts = col_cnts)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Ibxagzum6KJ","executionInfo":{"status":"ok","timestamp":1638748742421,"user_tz":300,"elapsed":7,"user":{"displayName":"Yixuan Meng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00008408025985696509"}},"outputId":"dd070bbb-9834-4129-a9d2-696fa8a2ccf0"},"source":["dummy_name\n","len(dummy_name)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["109"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"c-xTuORloL38"},"source":["class liar_dataset(Dataset):\n","  def __init__(self, dst, dummy_name):\n","    self.embedded = np.array(dst['embedded'])\n","    self.label = np.array(dst['label'])\n","    self.meta = np.array(dst[dummy_name])\n","  def __getitem__(self, index):\n","    return self.embedded[index],\\\n","          self.label[index],\\\n","          self.meta[index]\n","  def __len__(self):\n","    return len(self.label)\n","BATCH_SIZE = 64\n","train_dst = liar_dataset(train_dataset_meta, dummy_name)\n","train_data_iter = DataLoader(train_dst, batch_size=BATCH_SIZE, shuffle=True)\n","dev_dst = liar_dataset(dev_dataset_meta, dummy_name)\n","dev_data_iter = DataLoader(dev_dst, batch_size=BATCH_SIZE, shuffle=True)\n","test_dst = liar_dataset(test_dataset_meta, dummy_name)\n","test_data_iter = DataLoader(test_dst, batch_size=BATCH_SIZE, shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lz4JbGE7t3Ol"},"source":["def train(epoch,train_data_iter,dev_data_iter,opt,criteon, net, device):\n","  def timeSince(since):\n","      now = time.time()\n","      s = now - since\n","      m = math.floor(s / 60)\n","      s -= m * 60\n","      return '%dm %ds' % (m, s)\n","  train_losses, dev_losses, dev_acc_list = [], [], []\n","  best_model, best_val_acc = None, float('-inf')\n","  cnt_step = 0\n","  current_loss = 0\n","  plot_every = 2\n","  dev_every = 2\n","  print('train len:',len(train_data_iter),'dev len:',len(dev_data_iter))\n","  print('learning_rate',LEARNING_RATE,'n_iters',epoch, 'batch size', BATCH_SIZE, 'optim','Adam', 'lr_scheduler',None, 'device',device)\n","  start = time.time()\n","  for e in range(epoch): \n","    print('Epoch', e)\n","    net.train()\n","    for batch_idx, (text, label, meta) in enumerate(train_data_iter):\n","      # if text.shape[0]!=BATCH_SIZE:\n","        # continue\n","      text, label, meta = text.to(device), label.to(device), meta.to(device)\n","      output = net(text,meta)\n","      loss = criteon(output,label)\n","      current_loss += loss\n","      cnt_step += 1\n","      opt.zero_grad()\n","      loss.backward()\n","      opt.step()\n","    if e==0:\n","      print(time.time()-start)\n","    if e % plot_every == 0:\n","      tmp_loss = current_loss.item() / cnt_step\n","      train_losses.append(tmp_loss)\n","      current_loss, cnt_step = 0, 0\n","      print('%d %d%% (%s) %.4f ' % (e, e / EPOCH * 100, timeSince(start), tmp_loss))\n","    if e % dev_every ==0:\n","      net.eval()\n","      eval_loss = 0\n","      y_pred, y_true = [], []\n","      cnt_eval_step = 0\n","      for batch_idx, (text, label, meta) in enumerate(dev_data_iter):\n","        # if text.shape[0]!=BATCH_SIZE:\n","          # continue\n","        text, label, meta = text.to(device), label.to(device), meta.to(device)\n","        output = net(text, meta)\n","        categories = category_from_output(output)\n","        loss = criteon(output,label)\n","        eval_loss += loss\n","        cnt_eval_step += 1\n","\n","        y_pred += categories\n","        y_true += label.tolist()\n","      # print(cnt_eval_step, eval_loss, len(dev_data_iter))\n","      dev_losses.append(eval_loss.item()/cnt_eval_step)\n","      acc = accuracy_score(y_pred,y_true)\n","      dev_acc_list.append(acc)\n","      if acc>best_val_acc:\n","        best_val_acc = acc\n","        best_model = copy.deepcopy(net)\n","      print('%d %d%% (%s) %.4f %s %s %.4f' % (e, e / EPOCH * 100, timeSince(start), eval_loss.item()/cnt_eval_step, categories[:4], label.tolist()[:4], acc))\n","  print('best_val_acc',best_val_acc)\n","  return train_losses, dev_losses, dev_acc_list, best_model # best_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1M3nFz4q8-na"},"source":["from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","def evaluate_p_r_f1_acc(y_pred, y_true):\n","  precision = precision_score(y_pred, y_true)\n","  recall = recall_score(y_pred, y_true)\n","  fscore = f1_score(y_pred, y_true)\n","  acc = accuracy_score(y_pred, y_true)\n","  return precision, recall, fscore, acc\n","def evaluate_model(model, data_iter):\n","  # model.eval()\n","  y_pred, y_true = [], []\n","  for batch_idx, (text, label, meta) in enumerate(data_iter):\n","        # if text.shape[0]!=BATCH_SIZE:\n","          # continue\n","        text, label, meta = text.to(device), label.to(device), meta.to(device)\n","        output = model(text, meta)\n","        categories = category_from_output(output)\n","        loss = criteon(output,label)\n","\n","        y_pred += categories\n","        y_true += label.tolist()\n","        \n","  acc = accuracy_score(y_pred,y_true)\n","  print('acc: ', acc)\n","  # p,r,fscore, acc = evaluate_p_r_f1_acc(y_pred, y_true)\n","  # print('Precision: ',p, '\\tRecall: ',r,'\\tF-score: ',fscore,'\\tacc: ', acc)\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fE7HlJ08_ZKk"},"source":["## CNN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kfTKWtlmB04e","executionInfo":{"status":"ok","timestamp":1638750276459,"user_tz":300,"elapsed":275,"user":{"displayName":"Yixuan Meng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00008408025985696509"}},"outputId":"d9253c68-f45c-4fe2-ef65-ce90e63a1642"},"source":["\n","class hybridCNN2(nn.Module):\n","    def __init__(self, token_size, pretrained_emb):\n","        super(hybridCNN2, self).__init__()\n","        num_class = 6\n","        dropout_rate = 0.5\n","        self.ksizes = [5,5,5]\n","        print(dropout_rate,self.ksizes)\n","        self.embedding = nn.Embedding(\n","            num_embeddings=token_size,\n","            embedding_dim=300\n","        )\n","        self.embedding.weight.data.copy_(torch.from_numpy(pretrained_emb))\n","        self.conv_unit = nn.Sequential(\n","            nn.Conv1d(in_channels=300, out_channels=128, kernel_size=self.ksizes[0]),\n","            nn.Dropout(dropout_rate), nn.ReLU(),\n","            nn.Conv1d(in_channels=128, out_channels=128, kernel_size=self.ksizes[1]),\n","            # nn.Dropout(dropout_rate), nn.ReLU(),\n","            # nn.Conv1d(in_channels=128, out_channels=128, kernel_size=self.ksizes[2]),\n","            # nn.Dropout(dropout_rate), nn.ReLU(),\n","        )\n","        # self.convs = nn.ModuleList([nn.Conv2d(1, 100, (w, 200)) for w in kernel_wins])\n","        self.dropout = nn.Dropout(dropout_rate)\n","        self.fc = nn.Linear(128, num_class)\n","\n","    def forward(self, x, meta):\n","      # print('x',x.shape,'meta',meta.shape)\n","      x = self.embedding(x) # [4, len, 300] (4=bsz)\n","      x = torch.transpose(x,1,2)\n","      x = self.conv_unit(x) # x1: [4, 128, len_a]\n","      x = x.squeeze(-1) # x: [4, 128, len_d]\n","      x = self.dropout(x) # torch.Size([4, 128, len_d])\n","      x = x[:,:,-1] # [bsz, 128]\n","\n","      logit = self.fc(x) # [4, 6]\n","      return logit\n","      # fc1 = nn.Linear(meta.shape[1],2)\n","      # meta = fc1(meta.float())\n","      # output2 = torch.cat((x,meta), dim=1)\n","      # fc = nn.Linear(output2.shape[1], 6)\n","      # output3 = fc(output2)\n","      # return output3\n","    \n","# debug\n","net = hybridCNN2(len(token2ix), pretrained_emb).to(device)\n","criteon = nn.CrossEntropyLoss().to(device)\n","for batch_idx, (text, label, meta) in enumerate(train_data_iter):\n","    text, label, meta = text.to(device), label.to(device), meta.to(device)\n","    output = net(text,meta)\n","    loss = criteon(output,label)\n","    print('1',output.shape)\n","    break"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.5 [5, 5, 5]\n","1 torch.Size([64, 6])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"21FXtrj-B2sB","executionInfo":{"status":"ok","timestamp":1638750247256,"user_tz":300,"elapsed":239205,"user":{"displayName":"Yixuan Meng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00008408025985696509"}},"outputId":"7e4cca18-4470-4725-bf37-2c4fcba54271"},"source":["LEARNING_RATE = 0.0002\n","net = hybridCNN2(len(token2ix), pretrained_emb).to(device)\n","criteon = nn.CrossEntropyLoss().to(device)\n","opt = optimizer.Adam(net.parameters(), lr=LEARNING_RATE,weight_decay=1e-4)\n","train_losses, dev_losses, dev_acc_list, best_model = train(11,train_data_iter,dev_data_iter,opt,criteon, net, device)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.3 [5, 5, 5]\n","train len: 161 dev len: 21\n","learning_rate 0.0002 n_iters 11 batch size 64 optim Adam lr_scheduler None device cpu\n","Epoch 0\n","19.760735511779785\n","0 0% (0m 19s) 1.7641 \n","0 0% (0m 20s) 1.7757 [1, 1, 1, 1] [5, 1, 5, 2] 0.2002\n","Epoch 1\n","Epoch 2\n","2 18% (0m 59s) 1.7569 \n","2 18% (1m 0s) 1.7706 [1, 1, 1, 0] [4, 4, 2, 5] 0.2298\n","Epoch 3\n","Epoch 4\n","4 36% (1m 39s) 1.7488 \n","4 36% (1m 39s) 1.7608 [0, 1, 0, 0] [3, 2, 2, 4] 0.2336\n","Epoch 5\n","Epoch 6\n","6 54% (2m 19s) 1.7364 \n","6 54% (2m 19s) 1.7705 [3, 0, 1, 0] [3, 3, 0, 5] 0.2251\n","Epoch 7\n","Epoch 8\n","8 72% (3m 4s) 1.7075 \n","8 72% (3m 4s) 1.7767 [0, 0, 0, 0] [4, 3, 0, 2] 0.2188\n","Epoch 9\n","Epoch 10\n","10 90% (3m 58s) 1.6424 \n","10 90% (3m 59s) 1.8344 [0, 0, 0, 0] [1, 4, 5, 1] 0.2126\n","best_val_acc 0.2336448598130841\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ydM8SYfjGFmu","executionInfo":{"status":"ok","timestamp":1638750253961,"user_tz":300,"elapsed":1040,"user":{"displayName":"Yixuan Meng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00008408025985696509"}},"outputId":"bd665caf-bf45-462d-fa86-813d538e5064"},"source":["evaluate_model(best_model, dev_data_iter)\n","evaluate_model(best_model, test_data_iter)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["acc:  0.2336448598130841\n","acc:  0.2112236944660951\n"]}]},{"cell_type":"code","metadata":{"id":"JEz3pJGdG3Bz"},"source":["# torch.save(best_model.state_dict(), os.path.join(data_dir,'liar_CNN-acc2367-2182.pth'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sJwBpfMlDY-w","executionInfo":{"status":"ok","timestamp":1638750466504,"user_tz":300,"elapsed":19415,"user":{"displayName":"Yixuan Meng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00008408025985696509"}},"outputId":"0a563bf0-00f1-4809-c64f-a0bf6a420ca8"},"source":["X_train, y_train = np.array([np.array(i) for i in train_dataset['embedded']]),np.array(train_dataset['label'])\n","X_dev, y_dev = np.array([np.array(i) for i in dev_dataset['embedded']]),np.array(dev_dataset['label'])\n","X_test, y_test = np.array([np.array(i) for i in test_dataset['embedded']]),np.array(test_dataset['label'])\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","models = {'logistic':LogisticRegression(),'svm':SVC(C=1,)}\n","for m in models:\n","  print(m)\n","  model = models[m]\n","  model.fit(X_train,y_train)\n","  y_pred = model.predict(X_dev)\n","  print('dev',accuracy_score(y_pred,y_dev))\n","  y_pred = model.predict(X_test)\n","  print('test',accuracy_score(y_pred,y_test))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["logistic\n","dev 0.19626168224299065\n","test 0.21434138737334374\n","svm\n","dev 0.22741433021806853\n","test 0.1995323460639127\n"]}]},{"cell_type":"code","metadata":{"id":"AHNW-dSAMnKw"},"source":["for ker in ['linear','poly','rbf','sigmoid']:\n","  clf = SVC(kernel = ker)\n","  clf.fit(X_train, y_train)\n","  y_pred = clf.predict(X_dev)\n","  acc = accuracy_score(y_pred, y_dev)\n","  print('dev',accuracy_score(y_pred,y_dev))\n","  y_pred = model.predict(X_test)\n","  print('test',accuracy_score(y_pred,y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gnZjC4UWJphZ","executionInfo":{"status":"ok","timestamp":1638751450670,"user_tz":300,"elapsed":83154,"user":{"displayName":"Yixuan Meng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00008408025985696509"}},"outputId":"e432e84d-a567-49e7-8e86-1c9fad6a71a5"},"source":["gamma_space = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n","# c_space = [i/10 for i in range(5,15,2)]\n","for i,g in enumerate(gamma_space):\n","  c = c_space[4-i]\n","    # for c in c_space:\n","  print('g',g,'\\tc',c)\n","  clf = SVC(gamma = g)\n","  clf.fit(X_train, y_train)\n","  y_pred = clf.predict(X_dev)\n","  acc = accuracy_score(y_pred, y_dev)\n","  print('dev',accuracy_score(y_pred,y_dev))\n","  y_pred = model.predict(X_test)\n","  print('test',accuracy_score(y_pred,y_test))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["g 0.1 \tc 1.3\n","dev 0.1985981308411215\n","test 0.1995323460639127\n","g 0.2 \tc 1.1\n","dev 0.1985981308411215\n","test 0.1995323460639127\n","g 0.3 \tc 0.9\n","dev 0.1985981308411215\n","test 0.1995323460639127\n","g 0.4 \tc 0.7\n","dev 0.1985981308411215\n","test 0.1995323460639127\n","g 0.5 \tc 0.5\n","dev 0.19314641744548286\n","test 0.1995323460639127\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FscRhPobdFP9","executionInfo":{"status":"ok","timestamp":1638488201856,"user_tz":300,"elapsed":307,"user":{"displayName":"Yixuan Meng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00008408025985696509"}},"outputId":"93be69dd-8f2f-48ef-a674-12c8211dd952"},"source":["# bad strong baseline\n","class hybridCNN1(nn.Module):\n","    def __init__(self, token_size, pretrained_emb, hidden_dim=32, n_layers=2):\n","        super(hybridCNN1, self).__init__()\n","        num_class = 6\n","        dropout_rate = 0.5\n","        self.ksizes = [3,4,5]\n","        self.embedding = nn.Embedding(\n","            num_embeddings=token_size,\n","            embedding_dim=300\n","        )\n","        self.embedding.weight.data.copy_(torch.from_numpy(pretrained_emb))\n","        self.conv_unit = nn.Sequential(\n","            nn.Conv1d(in_channels=300, out_channels=128, kernel_size=self.ksizes[0]),\n","            nn.Dropout(0.8), nn.Relu(),\n","            nn.Conv1d(in_channels=128, out_channels=128, kernel_size=self.ksizes[1]),\n","            nn.Dropout(0.8), nn.Relu(),\n","            nn.Conv1d(in_channels=128, out_channels=128, kernel_size=self.ksizes[2]),\n","            nn.Dropout(0.8), nn.Relu(),\n","        )\n","\n","      \n","        self.conv_unit1 = nn.Sequential(\n","            torch.nn.Conv1d(in_channels=300, out_channels=128, kernel_size=self.ksizes[0]),\n","            torch.nn.MaxPool1d(kernel_size=self.ksizes[0]),\n","            # torch.nn.AdaptiveMaxPool1d(output_size),\n","        )\n","        self.conv_unit2 = nn.Sequential(\n","            torch.nn.Conv1d(in_channels=300, out_channels=128, kernel_size=self.ksizes[1]),\n","            torch.nn.MaxPool1d(kernel_size=self.ksizes[1]),\n","        )\n","        self.conv_unit3 = nn.Sequential(\n","            torch.nn.Conv1d(in_channels=300, out_channels=128, kernel_size=self.ksizes[2]),\n","            torch.nn.MaxPool1d(kernel_size=self.ksizes[2]),\n","        )\n","        # self.convs = nn.ModuleList([nn.Conv2d(1, 100, (w, 200)) for w in kernel_wins])\n","        self.dropout = nn.Dropout(dropout_rate)\n","        self.fc = nn.Linear(128, num_class)\n","\n","        self.hidden_dim = hidden_dim\n","        self.n_layers = n_layers\n","        self.rnn = nn.LSTM(300, hidden_dim, num_layers=n_layers, bidirectional=True, dropout=0.5)\n","        self.dropout = nn.Dropout(0.8)\n","\n","        self.meta_lstm = nn.LSTM(input_size=300, hidden_size = 5, num_layers = 2, \n","                                 batch_first = True, bidirectional = True)\n","        self.meta_lstm1 = nn.LSTM(input_size=35, hidden_size = 16, num_layers = 2, \n","                                 batch_first = True, bidirectional = True)\n","\n","    def forward(self, x, meta):\n","      # print('x',x.shape,'meta',meta.shape)\n","      x = self.embedding(x) # [4, len, 300] (4=bsz)\n","      x = torch.transpose(x,1,2)\n","      x1 = self.conv_unit1(x) # x1: [4, 128, len_a]\n","      x2 = self.conv_unit2(x) # x2: [4, 128, len_b]\n","      x3 = self.conv_unit3(x) # x3: [4, 128, len_c]\n","      x = torch.cat((x1,x2,x3), dim=2) # x: [4, 128, len_d]\n","      x = x.squeeze(-1) # x: [4, 128, len_d]\n","      x = self.dropout(x) # torch.Size([4, 128, len_d])\n","      x = x[:,:,-1] # [bsz, 128]\n","\n","      logit = self.fc(x) # [4, 6]\n","      return logit\n","      # fc1 = nn.Linear(meta.shape[1],2)\n","      # meta = fc1(meta.float())\n","      # output2 = torch.cat((x,meta), dim=1)\n","      # fc = nn.Linear(output2.shape[1], 6)\n","      # output3 = fc(output2)\n","      # return output3\n","    \n","# debug\n","net = hybridCNN1(len(token2ix), pretrained_emb).to(device)\n","criteon = nn.CrossEntropyLoss().to(device)\n","for batch_idx, (text, label, meta) in enumerate(train_data_iter):\n","    text, label, meta = text.to(device), label.to(device), meta.to(device)\n","    output = net(text,meta)\n","    loss = criteon(output,label)\n","    print('1',output.shape)\n","    break"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1 torch.Size([64, 6])\n"]}]},{"cell_type":"code","metadata":{"id":"pbi-7Jq25aQI"},"source":["LEARNING_RATE = 0.0005"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7UGo7lEcwj1H","executionInfo":{"status":"ok","timestamp":1638488536742,"user_tz":300,"elapsed":325652,"user":{"displayName":"Yixuan Meng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00008408025985696509"}},"outputId":"e774a751-1f5c-49c6-de63-b08b1e89c703"},"source":["net = hybridCNN1(len(token2ix), pretrained_emb).to(device)\n","criteon = nn.CrossEntropyLoss().to(device)\n","opt = optimizer.Adam(net.parameters(), lr=LEARNING_RATE)\n","train_losses, dev_losses, dev_acc_list, best_model = train(11,train_data_iter,dev_data_iter,opt,criteon, net, device)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train len: 161 dev len: 21\n","learning_rate 0.0005 n_iters 11 batch size 64 optim Adam lr_scheduler None device cpu\n","Epoch 0\n","29.711714267730713\n","0 0% (0m 29s) 1.8109 \n","0 0% (0m 30s) 1.7576 [1, 2, 1, 2] [1, 3, 3, 1] 0.2173\n","Epoch 1\n","Epoch 2\n","2 18% (1m 28s) 1.7730 \n","2 18% (1m 29s) 1.7641 [3, 3, 3, 0] [0, 2, 4, 4] 0.2274\n","Epoch 3\n","Epoch 4\n","4 36% (2m 30s) 1.7435 \n","4 36% (2m 31s) 1.7594 [0, 1, 0, 1] [2, 2, 2, 0] 0.2290\n","Epoch 5\n","Epoch 6\n","6 54% (3m 28s) 1.7203 \n","6 54% (3m 29s) 1.7578 [1, 1, 3, 1] [2, 2, 4, 4] 0.2220\n","Epoch 7\n","Epoch 8\n","8 72% (4m 26s) 1.6885 \n","8 72% (4m 27s) 1.7577 [0, 2, 0, 0] [4, 1, 2, 2] 0.2336\n","Epoch 9\n","Epoch 10\n","10 90% (5m 24s) 1.6257 \n","10 90% (5m 25s) 1.7691 [1, 0, 2, 2] [5, 0, 2, 2] 0.2235\n","best_val_acc 0.2336448598130841\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1-TBkpU4fC94","executionInfo":{"status":"ok","timestamp":1638488572269,"user_tz":300,"elapsed":1810,"user":{"displayName":"Yixuan Meng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00008408025985696509"}},"outputId":"1e289757-1c30-4cc7-9a6d-60de13350d84"},"source":["evaluate_model(best_model, dev_data_iter)\n","evaluate_model(best_model, test_data_iter)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["acc:  0.2336448598130841\n","acc:  0.20420888542478566\n"]}]},{"cell_type":"code","metadata":{"id":"mF-lH_OzBsyE"},"source":["torch.save(best_model.state_dict(), os.path.join(data_dir,'liar_CNN-acc2328-2135.pth'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1bbEq7HQdWZ2","executionInfo":{"status":"ok","timestamp":1638487613640,"user_tz":300,"elapsed":1051,"user":{"displayName":"Yixuan Meng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00008408025985696509"}},"outputId":"8dce99f2-8dc2-4512-a9d7-1624bf9b93b2"},"source":["best_model = hybridCNN1(len(token2ix), pretrained_emb)\n","criteon = nn.CrossEntropyLoss().to(device)\n","opt = optimizer.Adam(net.parameters(), lr=LEARNING_RATE)\n","model_path = os.path.join(data_dir, 'liar_CNN-acc2336.pth')\n","best_model.load_state_dict(torch.load(model_path))\n","evaluate_model(best_model, dev_data_iter)\n","evaluate_model(best_model, test_data_iter)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["acc:  0.21728971962616822\n"]}]},{"cell_type":"code","metadata":{"id":"7OImYlTLYSt8"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lGmceHF-YTgv"},"source":["## Previous"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jUahU14LAUNc","executionInfo":{"status":"ok","timestamp":1638645062585,"user_tz":300,"elapsed":1034,"user":{"displayName":"Yixuan Meng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00008408025985696509"}},"outputId":"cb125b4c-989a-4018-cc90-fec36d29017a"},"source":["# trying\n","class hybrid_BiLSTM_Attention(nn.Module):\n","    def __init__(self, token_size, pretrained_emb, hidden_dim=128, n_layers=2):\n","        super(hybrid_BiLSTM_Attention, self).__init__()\n","        self.embedding = nn.Embedding(\n","            num_embeddings=token_size,\n","            embedding_dim=300\n","        )\n","        print('hidden_dim',hidden_dim)\n","        self.embedding.weight.data.copy_(torch.from_numpy(pretrained_emb).type(torch.float))\n","\n","        self.hidden_dim = hidden_dim\n","        self.n_layers = n_layers\n","        self.rnn = nn.LSTM(300, hidden_dim, num_layers=n_layers, bidirectional=True, dropout=0.5)\n","        self.dropout = nn.Dropout(0.5)\n","\n","        self.w_omega = nn.Parameter(torch.Tensor(hidden_dim * 2, hidden_dim * 2))\n","        self.u_omega = nn.Parameter(torch.Tensor(hidden_dim * 2, 1))\n","\n","        nn.init.uniform_(self.w_omega, -0.1, 0.1)\n","        nn.init.uniform_(self.u_omega, -0.1, 0.1)\n","        self.fc = nn.Linear(hidden_dim * 2, 6)\n","        \n","\n","    def attention_net(self, x):       #x:[batch, seq_len, hidden_dim*2]\n","        u = torch.tanh(torch.matmul(x, self.w_omega))         #[batch, seq_len, hidden_dim*2]\n","        att = torch.matmul(u, self.u_omega)                   #[batch, seq_len, 1]\n","        att_score = F.softmax(att, dim=1)\n","        scored_x = x * att_score                              #[batch, seq_len, hidden_dim*2]\n","        context = torch.sum(scored_x, dim=1)                  #[batch, hidden_dim*2]\n","        # print('context',context.shape)\n","        return context\n","\n","    def forward(self, x, meta):\n","        # print(x.shape,meta.shape)\n","        embedding = self.dropout(self.embedding(x))       #[seq_len, batch, embedding_dim]\n","        embedding = torch.transpose(embedding,0,1)\n","        # output: [seq_len, batch, hidden_dim*2]     hidden/cell: [n_layers*2, batch, hidden_dim]\n","        output, (final_hidden_state, final_cell_state) = self.rnn(embedding)\n","        output = output.permute(1, 0, 2)                  #[batch, seq_len, hidden_dim*2]\n","        attn_output = self.attention_net(output)\n","        # print(attn_output.shape)\n","        # logit = self.fc(attn_output)\n","        # return logit\n","        # print(attn_output)\n","\n","        fc1 = nn.Linear(meta.shape[1],128)\n","        meta = fc1(meta.float())\n","\n","        # meta_emb = \n","        # meta_lstm = nn.LSTM(meta.shape[1], hidden_size=64, num_layers=1, dropout=0.5)\n","        # meta = meta_lstm(meta.float())\n","        # print(meta.shape)\n","        # print(meta)\n","\n","        output2 = torch.cat((attn_output,meta), dim=1)\n","        fc = nn.Linear(output2.shape[1], 6)\n","        output3 = fc(output2)\n","        return output3\n","# bilstm_hidden = 32\n","bilstm = hybrid_BiLSTM_Attention(len(token2ix), pretrained_emb).to(device)\n","criteon = nn.CrossEntropyLoss().to(device)\n","for batch_idx, (text, label, meta) in enumerate(train_data_iter):\n","    text, label, meta = text.to(device), label.to(device), meta.to(device)\n","    # cnnnet = BiLSTM_Attention(len(token2ix), pretrained_emb).to(device)\n","    # print(meta.shape)\n","    output = bilstm(meta.long(),meta)\n","    # output1 = cnnnet(text, meta)\n","    # output2 = torch.cat((output,output1), dim=1)\n","    # print('0',output2.shape)\n","    # fc = nn.Linear(output2.shape[1], 6)\n","    # output3 = fc(output2)\n","    # print('1',output3.shape)\n","    loss = criteon(output,label)\n","    break"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["hidden_dim 128\n"]}]},{"cell_type":"code","metadata":{"id":"kkp3rrpYAaSU"},"source":["LEARNING_RATE = 0.001"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3FK-BnVnAdYO","executionInfo":{"status":"ok","timestamp":1638645152622,"user_tz":300,"elapsed":88572,"user":{"displayName":"Yixuan Meng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00008408025985696509"}},"outputId":"31a8ac05-3c67-484c-bbe6-51a23cc0cbc2"},"source":["net = hybrid_BiLSTM_Attention(len(token2ix), pretrained_emb).to(device)\n","criteon = nn.CrossEntropyLoss().to(device)\n","opt = optimizer.Adam(net.parameters(), lr=LEARNING_RATE)\n","train_losses, dev_losses, dev_acc_list, best_model = train(1,train_data_iter,dev_data_iter,opt,criteon, net, device)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["hidden_dim 128\n","train len: 161 dev len: 21\n","learning_rate 0.001 n_iters 1 batch size 64 optim Adam lr_scheduler None device cpu\n","Epoch 0\n","84.79648303985596\n","0 0% (1m 24s) 3.4699 \n","0 0% (1m 28s) 3.4764 [20, 20, 20, 20] [4, 0, 4, 5] 0.0413\n","best_val_acc 0.04127725856697819\n"]}]},{"cell_type":"markdown","metadata":{"id":"EkxWRYHe_3oB"},"source":["## BiLSTM"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y8eOmHhAsa9Y","executionInfo":{"status":"ok","timestamp":1638478489546,"user_tz":300,"elapsed":579,"user":{"displayName":"Yixuan Meng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00008408025985696509"}},"outputId":"a35f5862-d040-4813-e47a-696a363e58cc"},"source":["class BiLSTM_Attention(nn.Module):\n","    def __init__(self, token_size, pretrained_emb, hidden_dim=64, n_layers=2):\n","        super(BiLSTM_Attention, self).__init__()\n","        self.embedding = nn.Embedding(\n","            num_embeddings=token_size,\n","            embedding_dim=300\n","        )\n","        print('hidden_dim',hidden_dim)\n","        self.embedding.weight.data.copy_(torch.from_numpy(pretrained_emb).type(torch.float))\n","\n","        self.hidden_dim = hidden_dim\n","        self.n_layers = n_layers\n","        self.rnn = nn.LSTM(300, hidden_dim, num_layers=n_layers, bidirectional=True, dropout=0.5)\n","        self.dropout = nn.Dropout(0.5)\n","\n","        self.w_omega = nn.Parameter(torch.Tensor(hidden_dim * 2, hidden_dim * 2))\n","        self.u_omega = nn.Parameter(torch.Tensor(hidden_dim * 2, 1))\n","\n","        nn.init.uniform_(self.w_omega, -0.1, 0.1)\n","        nn.init.uniform_(self.u_omega, -0.1, 0.1)\n","        self.fc = nn.Linear(hidden_dim * 2, 6)\n","        \n","\n","    def attention_net(self, x):       #x:[batch, seq_len, hidden_dim*2]\n","        u = torch.tanh(torch.matmul(x, self.w_omega))         #[batch, seq_len, hidden_dim*2]\n","        att = torch.matmul(u, self.u_omega)                   #[batch, seq_len, 1]\n","        att_score = F.softmax(att, dim=1)\n","        scored_x = x * att_score                              #[batch, seq_len, hidden_dim*2]\n","        context = torch.sum(scored_x, dim=1)                  #[batch, hidden_dim*2]\n","        # print('context',context.shape)\n","        return context\n","\n","    def forward(self, x, meta):\n","        # print(x.shape,meta.shape)\n","        embedding = self.dropout(self.embedding(x))       #[seq_len, batch, embedding_dim]\n","        embedding = torch.transpose(embedding,0,1)\n","        # output: [seq_len, batch, hidden_dim*2]     hidden/cell: [n_layers*2, batch, hidden_dim]\n","        output, (final_hidden_state, final_cell_state) = self.rnn(embedding)\n","        output = output.permute(1, 0, 2)                  #[batch, seq_len, hidden_dim*2]\n","        attn_output = self.attention_net(output)\n","        \n","        logit = self.fc(attn_output)\n","        return logit\n","\n","        fc1 = nn.Linear(meta.shape[1],16)\n","        meta = fc1(meta.float())\n","        # print(meta.shape)\n","\n","        output2 = torch.cat((attn_output,meta), dim=1)\n","        fc = nn.Linear(output2.shape[1], 6)\n","        output3 = fc(output2)\n","        return output3\n","# bilstm_hidden = 32\n","bilstm = BiLSTM_Attention(len(token2ix), pretrained_emb).to(device)\n","criteon = nn.CrossEntropyLoss().to(device)\n","for batch_idx, (text, label, meta) in enumerate(train_data_iter):\n","    text, label, meta = text.to(device), label.to(device), meta.to(device)\n","    cnnnet = BiLSTM_Attention(len(token2ix), pretrained_emb).to(device)\n","    # print(meta.shape)\n","    output = bilstm(meta.long(),meta)\n","    # output1 = cnnnet(text, meta)\n","    # output2 = torch.cat((output,output1), dim=1)\n","    # print('0',output2.shape)\n","    # fc = nn.Linear(output2.shape[1], 6)\n","    # output3 = fc(output2)\n","    # print('1',output3.shape)\n","    loss = criteon(output,label)\n","    break"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["hidden_dim 64\n","hidden_dim 64\n"]}]},{"cell_type":"code","metadata":{"id":"S6-OW5SI5YJJ"},"source":["LEARNING_RATE = 0.001"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QwWRhlq37m73"},"source":["LEARNING_RATE = 2e-5 # 0.00002"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"132MoX_4_3O0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ahe2JvJj25D4","executionInfo":{"status":"ok","timestamp":1638479310242,"user_tz":300,"elapsed":293302,"user":{"displayName":"Yixuan Meng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00008408025985696509"}},"outputId":"3c34a201-d783-4ee3-8e28-0663f9fb27aa"},"source":["net = BiLSTM_Attention(len(token2ix), pretrained_emb).to(device)\n","criteon = nn.CrossEntropyLoss().to(device)\n","opt = optimizer.Adam(net.parameters(), lr=LEARNING_RATE)\n","train_losses, dev_losses, dev_acc_list, best_model = train(11,train_data_iter,dev_data_iter,opt,criteon, net, device)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["hidden_dim 64\n","train len: 161 dev len: 21\n","learning_rate 0.001 n_iters 11 batch size 64 optim Adam lr_scheduler None device cpu\n","Epoch 0\n","28.021397352218628\n","0 0% (0m 28s) 1.7459 \n","0 0% (0m 29s) 1.7246 [1, 1, 1, 0] [3, 4, 5, 4] 0.2469\n","Epoch 1\n","Epoch 2\n","2 18% (1m 20s) 1.6521 \n","2 18% (1m 21s) 1.7357 [0, 2, 2, 0] [0, 3, 1, 2] 0.2671\n","Epoch 3\n","Epoch 4\n","4 36% (2m 11s) 1.4083 \n","4 36% (2m 12s) 1.9078 [1, 5, 1, 0] [1, 4, 4, 5] 0.2570\n","Epoch 5\n","Epoch 6\n","6 54% (3m 3s) 1.1335 \n","6 54% (3m 4s) 2.2464 [3, 0, 2, 3] [4, 1, 2, 5] 0.2414\n","Epoch 7\n","Epoch 8\n","8 72% (3m 57s) 0.9084 \n","8 72% (3m 58s) 2.5837 [2, 3, 5, 4] [1, 2, 0, 1] 0.2422\n","Epoch 9\n","Epoch 10\n","10 90% (4m 51s) 0.7392 \n","10 90% (4m 52s) 2.7517 [2, 0, 0, 1] [2, 4, 3, 4] 0.2360\n","best_val_acc 0.26713395638629284\n"]}]},{"cell_type":"code","metadata":{"id":"fupL-9aF8mPo"},"source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","fig, ((ax1, ax2))= plt.subplots(1,2,figsize = (15,5))\n","x_axis = [i*2 for i in range(len(dev_losses))]\n","sns.lineplot(x_axis, dev_acc_list, ax = ax1)\n","ax1.set_ylabel('Accuracy')\n","ax1.set_xlabel(\"Number of Iterations\")\n","sns.lineplot(x_axis, train_losses, ax = ax2, label = 'train loss')\n","sns.lineplot(x_axis, dev_losses, ax = ax2, label = 'dev loss')\n","ax2.set_ylabel(\"Loss\")\n","ax2.set_xlabel(\"Number of Iterations\")\n","ax2.legend()\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cjgwOfV08S_4"},"source":["# torch.save(best_model.state_dict(), os.path.join(data_dir,'liar_biLSTM-acc2671.pth'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1abwSajx8_NV","executionInfo":{"status":"ok","timestamp":1638479610874,"user_tz":300,"elapsed":1246,"user":{"displayName":"Yixuan Meng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00008408025985696509"}},"outputId":"b91d5b7c-d6ab-4670-fb33-7979cbc74e4d"},"source":["evaluate_model(best_model, dev_data_iter)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["acc:  0.26713395638629284\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gw0DRPrj_iGB","executionInfo":{"status":"ok","timestamp":1638479618247,"user_tz":300,"elapsed":1240,"user":{"displayName":"Yixuan Meng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00008408025985696509"}},"outputId":"ab2c278c-7457-4758-df2f-6e52ed5bc761"},"source":["evaluate_model(best_model, test_data_iter)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["acc:  0.2720187061574435\n"]}]},{"cell_type":"code","metadata":{"id":"LvSq61qTL6HB"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QKUXT4KcnBxO","executionInfo":{"status":"ok","timestamp":1637955223913,"user_tz":300,"elapsed":338,"user":{"displayName":"Yixuan Meng","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00008408025985696509"}},"outputId":"98cf0799-d774-4348-813f-d275b1fe1849"},"source":["class hybridCNN(nn.Module):\n","    def __init__(self, token_size, pretrained_emb, hidden_dim=32, n_layers=2):\n","        super(hybridCNN, self).__init__()\n","        num_class = 6\n","        dropout_rate = 0.5\n","        ksizes = [3,3,3]\n","        self.embedding = nn.Embedding(\n","            num_embeddings=token_size,\n","            embedding_dim=300\n","        )\n","        self.embedding.weight.data.copy_(torch.from_numpy(pretrained_emb))\n","        self.conv_unit1 = nn.Sequential(\n","            torch.nn.Conv1d(in_channels=300, out_channels=128, kernel_size=ksizes[0]),\n","            torch.nn.MaxPool1d(kernel_size=ksizes[0]),\n","            # torch.nn.AdaptiveMaxPool1d(output_size),\n","        )\n","        self.conv_unit2 = nn.Sequential(\n","            torch.nn.Conv1d(in_channels=300, out_channels=128, kernel_size=ksizes[1]),\n","            torch.nn.MaxPool1d(kernel_size=ksizes[1]),\n","        )\n","        self.conv_unit3 = nn.Sequential(\n","            torch.nn.Conv1d(in_channels=300, out_channels=128, kernel_size=ksizes[2]),\n","            torch.nn.MaxPool1d(kernel_size=ksizes[2]),\n","        )\n","        # self.convs = nn.ModuleList([nn.Conv2d(1, 100, (w, 200)) for w in kernel_wins])\n","        self.dropout = nn.Dropout(dropout_rate)\n","        self.fc = nn.Linear(128, num_class)\n","\n","        self.hidden_dim = hidden_dim\n","        self.n_layers = n_layers\n","        self.rnn = nn.LSTM(300, hidden_dim, num_layers=n_layers, bidirectional=True, dropout=0.5)\n","        self.dropout = nn.Dropout(0.8)\n","\n","        self.w_omega = nn.Parameter(torch.Tensor(hidden_dim * 2, hidden_dim * 2))\n","        self.u_omega = nn.Parameter(torch.Tensor(hidden_dim * 2, 1))\n","\n","        nn.init.uniform_(self.w_omega, -0.1, 0.1)\n","        nn.init.uniform_(self.u_omega, -0.1, 0.1)\n","    def attention_net(self, x):       #x:[batch, seq_len, hidden_dim*2]\n","      u = torch.tanh(torch.matmul(x, self.w_omega))         #[batch, seq_len, hidden_dim*2]\n","      att = torch.matmul(u, self.u_omega)                   #[batch, seq_len, 1]\n","      att_score = F.softmax(att, dim=1)\n","      scored_x = x * att_score                              #[batch, seq_len, hidden_dim*2]\n","      context = torch.sum(scored_x, dim=1)                  #[batch, hidden_dim*2]\n","      # print('context',context.shape)\n","      return context\n","      \n","    def forward(self, x, meta):\n","      x = self.embedding(x) # [4, len, 300] (4=bsz)\n","      x = torch.transpose(x,1,2)\n","      x1 = self.conv_unit1(x) # x1: [4, 128, len_a]\n","      x2 = self.conv_unit2(x) # x2: [4, 128, len_b]\n","      x3 = self.conv_unit3(x) # x3: [4, 128, len_c]\n","      x = torch.cat((x1,x2,x3), dim=2) # x: [4, 128, len_d]\n","      x = x.squeeze(-1) # x: [4, 128, len_d]\n","      x = self.dropout(x) # torch.Size([4, 128, len_d])\n","      x = x[:,:,-1] # [bsz, 128]\n","\n","      logit = self.fc(x) # [4, 6]\n","      return logit\n","\n","      embedding = self.dropout(self.embedding(meta.long()))\n","      embedding = torch.transpose(embedding,0,1)\n","      output, (final_hidden_state, final_cell_state) = self.rnn(embedding)\n","      output = output.permute(1, 0, 2)                  #[batch, seq_len, hidden_dim*2]\n","      attn_output = self.attention_net(output)\n","      \n","      output2 = torch.cat((x,attn_output), dim=1)\n","      fc = nn.Linear(output2.shape[1], 6)\n","      output3 = fc(output2)\n","      return output3\n","\n","\n","      # self.conv_unit = nn.ModuleList()\n","      # for kernel_ in self.ksizes:\n","      #   self.conv_unit.append(nn.Conv2d(x.shape[0], 14, (kernel_, 300)))\n","      # statement_ = self.embedding(x).unsqueeze(0) # 1*W*D -> 1*1*W*D\n","      # statement_ = [F.relu(conv(statement_)).squeeze(3) for conv in self.conv_unit] # 1*1*W*1 -> 1*Conv-filters*(W-1) x len(convs)\n","      # statement_ = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in statement_] # 1*Conv-filters*1 -> 1*Conv-filters x len(convs)\n","      # statement_ = torch.cat(statement_, 1)  # 1*len(convs)\n","      # # print(statement_.shape)\n","\n","      # embedding = self.embedding(meta.long()).squeeze(0) # [bsz, len, emb-dim]\n","      # # print(embedding.shape)\n","      # embedding = torch.transpose(embedding,1,2)\n","      # x1 = self.conv_unit1(embedding)\n","      # # print(x1.shape)\n","      # _, (meta, _) = self.meta_lstm1(x1) # (layer x dir) * batch * hidden\n","      # # print(meta.shape)\n","      # meta = F.max_pool1d(meta, 16)\n","      # # print(meta.shape)\n","      # meta = meta.view(meta.shape[1], -1)\n","\n","      # output2 = torch.cat((x,meta), dim=1)\n","    \n","# debug\n","net = hybridCNN(len(token2ix), pretrained_emb).to(device)\n","criteon = nn.CrossEntropyLoss().to(device)\n","for batch_idx, (text, label, meta) in enumerate(train_data_iter):\n","    text, label, meta = text.to(device), label.to(device), meta.to(device)\n","    output = net(text,meta)\n","    loss = criteon(output,label)\n","    print('1',output.shape)\n","    break"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1 torch.Size([64, 6])\n"]}]}]}